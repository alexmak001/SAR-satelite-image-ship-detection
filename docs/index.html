<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Maritime Ship Detection Using Synthetic Aperture Radar Satellite Imagery</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<!-- <li><a href="#intro">Abstract</a></li> -->
							<li><a href="#introduction">Introduction</a></li>
							<li><a href="#applications">Applications</a></li>
							<!-- <li><a href="#one">one</a></li> -->
							<li><a href="#methods">Methods</a></li>
							<!-- <li><a href="#three">three</a></li> -->
							<li><a href="#results">Results</a></li>
							<li><a href="#conclusion">Conclusion</a></li>
							<li><a href="about.html">About</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Abstract -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>Maritime Ship Detection Using Synthetic Aperture Radar Satellite Imagery</h1>
							<p>A tool to count vessels in any part of the world using open sourced data</p>
							<p>By: Alexander Makhratchev and Sean Ng</p>
							
							<!-- <ul class="actions">
								<li><a href="#one" class="button scrolly">Learn more</a></li>
							</ul> -->
						</div>
					</section>
					
				<!-- Introduction -->	
					<section id="introduction" class="wrapper style1 fade-up">
						<div class="inner">
							<h1>Introduction</h2>
							<p> Satellites are being launched into space at an 
								exponential rate and are able to produce high quality 
								images in relatively short intervals of time 
								on any part of Earth. The amount of data and 
								types of it are also increasing significantly
								 and in this paper we specifically use Synthetic 
								 Aperture Radar (SAR) satellite imagery in order 
								 to detect ships traveling through bodies of water. 
								 We created a ship counting tool that intakes a start 
								 date, end date, and an area of interest and returns the number 
								 of ships for each day between the two dates. We propose a new 
								 method where the images are first classified into 
								 offshore or inshore and a separate object detection
								  algorithm counts the number of ships per image. 
								  The classifier and object detection networks are
								   trained using the Large-Scale SAR Ship Detection
								    Dataset-v1.0 (LS-SSDD-v1.0) and deployed on Google Earth Engine. We will be 
									using ships and vessels interchangeably throughout the report.
							</p>
							
					</section>

				<!-- Applications -->	
				<section id="applications" class="wrapper style1 fade-up">
					<div class="inner">
						<h1>Applications</h2>

						<!-- Port LA-->
						<div id="content1" class="content active">
							
							<div id='image-container' class = "split style1">
								<!-- have section here to keep style-->
								<section>
									<ul>
										<!--sub-buttons to switch between time frames within a place-->
										<li style="display:inline"><button class='sub_button' id="portla_before_covid" data-image="images/feb2020_portla.jpg" 
											data-caption="Ship Count: 52; Date: February 04, 2020. Majority of the offshore ships are detected 
											and that there are only a few incorrect detections inshore.">Before COVID Lockdown</button></li>

										<li style="display:inline"><button class='sub_button' id="portla_during_covid" data-image="images/mar2020_portla.jpg" 
											data-caption="Ship Count: 33; Date: March 17, 2020. Even though it is the same place, it is slightly 
											bright which causes some new objects to be detected as ships. The effects of the lockdown are evident with the 
											lower ship count within the port.">During COVID Lockdown</button></li>
										
										</ul>

										<img src="images/feb2020_portla.jpg" alt="Image 1" class='port_la_pic'>
										<div style="width:image width px; font-size:100%; text-align:center;" id="img_caption">Ship Count: 52; 
											Date: February 04, 2020. Most of the ships on the sea are counted correctly and 
											that there are only a few misclassifications inland. 
											<br><br>
											<i>Unfortunately we did not have ground truths for any of our
												application examples, therefore we cannot provide a quantitative measure of how well our tool does in deployment.  
											</i></div>
										
								</section>
							
								<section>
									<div class = 'button-container'>
										<ul class="places">
											<li><button id='button1' class = "active-button" onclick="showContent(1)" data-image="images/feb2020_portla.jpg" 
												data-caption="Ship Count: 52; Date: February 04, 2020. Majority of the offshore ships are detected 
												and that there are only a few incorrect detections inshore.">Port of Los Angeles</button></li>

											<li><button id='button2' onclick="showContent(2)" data-image="images/before_suez.jpg" 
												data-caption="Ship Count: 44; Date: March 20, 2021. We can see that the tool has no issues detecting ships
												in the open sea, but struggles with detecting ships near land as evident in the top right 
												corner of the image.">Suez Canal</button></li>

											<li><button  id='button3' onclick="showContent(3)" data-image="images/sg_start.jpg" 
												data-caption="Ship Count: 249; Date: January 7, 2020. 
												These iamges of the port of Singapore are overall brighter because there are more metallic buildings inland
												causing the SAR signal to be reflected in a manner similar to ships. Our tool is unable to detect ships
												under a certain size, which is a limitation of our tool.">Port of Singapore</button></li>
										</ul>
									</div>
								</section>
							</div>
						</div>

						<!-- Suez Canal -->
						<div id="content2" class="content">
							<div id='image-container1' class = "split style1">
								<section>
									<ul>
										<li style="display:inline"><button class='sub_button' id="place2_1" data-image="images/before_suez.jpg" 
											data-caption="Ship Count: 44; Date: March 20, 2021. We can see that the tool has no issues detecting ships
											in the open sea, but struggles with detecting ships near land as evident in the top right 
											corner of the image.">Before Suez Blockage by Ever Given Ship</button></li>

										<li style="display:inline"><button class='sub_button' id="place2_2" data-image="images/during_suez.jpg" 
											data-caption="Ship Count: 95; Date: March 25, 2021. Though our tool does not detect it,
											 the Ever Given ship can be found in the top right corner of the 
											image blocking the canal. Due to the blockage, the number of ships increases significantly.">During Suez Blockage by Ever Given Ship</button></li>

										<li style="display:inline"><button class='sub_button' id="place2_3" data-image="images/after_suez.jpg" 
											data-caption="Ship Count: 54; Date: April 11, 2021. 
											Ships are able to pass through the canal once again, and some are even detected inside the canal. The 
											ship traffic is reduced as well. ">After Suez Blockage by Ever Given Ship</button></li>
										</ul>

									<p><img src="images/before_suez.jpg" alt="Image 1" class="suez_canal_pic"></p>
									<div style="width:image width px; font-size:100%; text-align:center;" id="img_caption1">Ship Count: 44; Date: March 20, 2021</div>
								</section>
							
								<section>
									<div class = 'button-container'>
										<ul class="places">
											<li><button id='button1' onclick="showContent(1)" data-image="images/feb2020_portla.jpg" 
												data-caption="Ship Count: 52; Date: February 04, 2020. Majority of the offshore ships are detected 
												and that there are only a few incorrect detections inshore.">Port of Los Angeles</button></li>

											<li><button id='button2' class = "active-button" onclick="showContent(2)" data-image="images/before_suez.jpg" 
												data-caption="Ship Count: 44; Date: March 20, 2021. We can see that the tool has no issues detecting ships
												in the open sea, but struggles with detecting ships near land as evident in the top right 
												corner of the image.">Suez Canal</button></li>

											<li><button id='button3' onclick="showContent(3)" data-image="images/sg_start.jpg" 
												data-caption="Ship Count: 249; Date: January 7, 2020. 
												These iamges of the port of Singapore are overall brighter because there are more metallic buildings inland
												causing the SAR signal to be reflected in a manner similar to ships. Our tool is unable to detect ships
												under a certain size, which is a limitation of our tool.">Port of Singapore</button></li>
										</ul>
									</div>
								</section>
							</div>
							
						</div>

						<!-- Singapore -->
						<div id="content3" class="content">
							
							<div id='image-container2' class = "split style1">
								<!-- have section here to keep style-->
								<section>
									<ul>
										<!--sub-buttons to switch between time frames within a place-->
										<li style="display:inline"><button class='sub_button' id="sg_before_covid" data-image="images/sg_start.jpg" 
											data-caption="Ship Count: 249; Date: January 7, 2020. 
											These iamges of the port of Singapore are overall brighter because there are more metallic buildings inland
											causing the SAR signal to be reflected in a manner similar to ships. Our tool is unable to detect ships
											under a certain size, which is a limitation of our tool.">Before COVID Lockdown</button></li>

										<li style="display:inline"><button class='sub_button' id="sg_during_covid" data-image="images/sg_end.jpg" 
											data-caption="Ship Count: 288; Date: April 13, 2020. 
											Surprinsigly international lockdowns did not decrease the number of ships within the port. The tool also
											made less incorrect inland detections compared to previous applications.">During COVID Lockdown</button></li>
										
										</ul>
									<p><img src="images/sg_start.jpg" alt="Image 1" class='sg_pic'></p>
									<div style="width:image width px; font-size:100%; text-align:center;" id="img_caption2">Ship Count: 249; Date: January 7, 2020</div>
								</section>
							
								<section>
									<div class = 'button-container'>
										<ul class="places">
											<li><button id='button1' onclick="showContent(1)" data-image="images/feb2020_portla.jpg" 
												data-caption="Ship Count: 52; Date: February 04, 2020. Majority of the offshore ships are detected 
												and that there are only a few incorrect detections inshore.">Port of Los Angeles</button></li>

											<li><button id='button2' onclick="showContent(2)" data-image="images/before_suez.jpg" 
												data-caption="Ship Count: 44; Date: March 20, 2021. We can see that the tool has no issues detecting ships
												in the open sea, but struggles with detecting ships near land as evident in the top right 
												corner of the image.">Suez Canal</button></li>

											<li><button id='button3' class = "active-button" onclick="showContent(3)" data-image="images/sg_start.jpg" 
												data-caption="Ship Count: 249; Date: January 7, 2020. 
												These iamges of the port of Singapore are overall brighter because there are more metallic buildings inland
												causing the SAR signal to be reflected in a manner similar to ships. Our tool is unable to detect ships
												under a certain size, which is a limitation of our tool.">Port of Singapore</button></li>
										</ul>
									</div>
								</section>
							</div>
						</div>



						<style type="text/css">
							/* Style for the content divs */
							.content {
								display: none;
								/* padding: 10px; */
								/* border: 1px solid #ddd; */
								/* border-radius: 5px; */
								/* margin-top: 20px; */
							}
					
							/* Style for the active content div */
							.active {
								display: block;
							}
					
							/* Style for the button container */
							.button-container {
								margin-top: 20px;
							}
					
							
						</style>

						<script type="text/javascript">
							function showContent(num) {

								const img = document.querySelector('#image-container img');
								const img1 = document.querySelector('#image-container1 img');
								const im2 = document.querySelector('#image-container2 img')

								const cap = document.getElementById('img_caption')
								const cap1 = document.getElementById('img_caption1')
								const cap2 = document.getElementById('img_caption2')
								// Hide all content divs
								var contents = document.getElementsByClassName("content");
								for (var i = 0; i < contents.length; i++) {
									contents[i].classList.remove("active");
								}

								// Remove the 'active-button' class from all buttons
								var buttons = document.getElementsByTagName("button");
								for (var i = 0; i < buttons.length; i++) {
									buttons[i].classList.remove("active-button");
								}

								// Show the selected content div and add the 'active-button' class to the clicked button
								var selectedContent = document.getElementById("content" + num);
								selectedContent.classList.add("active");
								var clickedButton = document.getElementById("button" + num);
								clickedButton.classList.add("active-button");

								// have these here to make sure even after using sub buttons to swtich, it'll switch back to original picture
								img.src = clickedButton.dataset.image;
								img.alt = clickedButton.textContent;

								img1.src = clickedButton.dataset.image;
								img1.alt = clickedButton.textContent;

								img2.src = clickedButton.dataset.image;
								img2.alt = clickedButton.textContent;

								cap.innerHTML = clickedButton.dataset.caption
								cap1.innerHTML = clickedButton.dataset.caption
								cap2.innerHTML = clickedButton.dataset.caption

								
							}
						</script>

						
						<!-- Script for changing image with sub-buttons -->
						   <script>
							const buttons = document.querySelectorAll('.sub_button');
							const img = document.querySelector('#image-container img');
							const img1 = document.querySelector('#image-container1 img');
							const img2 = document.querySelector('#image-container2 img');
							const cap = document.getElementById('img_caption')
							const cap1 = document.getElementById('img_caption1')
							const cap2 = document.getElementById('img_caption2')
						  
							buttons.forEach(button => {
							  button.addEventListener('click', () => {
								cap.innerHTML = button.dataset.caption
								cap1.innerHTML = button.dataset.caption
								cap2.innerHTML = button.dataset.caption

								img.src = button.dataset.image;
								img.alt = button.textContent;

								img1.src = button.dataset.image;
								img1.alt = button.textContent;

								img2.src = button.dataset.image;
								img2.alt = button.textContent;
							  });
							});

						  </script> 

						  
						
				</section>
				
				<!-- Methods -->	
				<section id="methods" class="wrapper style1 fade-up">
					<div class="inner">

							<h1>Methods</h1>
							<h2>Full Pipeline</h2>
								<img src="images/Workflow.jpg" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">Workflow Diagram</div>
								<p>
									<br>
									To obtain the count of ships within an image, we have broken our pipeline down into 5 major steps. Our final workflow is as follows: 
									<ol>
										<li>The first step of the process is to acquire images from Google Earth Engine. The user can input the coordinates
											of their area of interest as well as the desired start and end dates into the ship counting script and will start downloading the images.
										</li>
											<ul>
												<li><i>(For a more detailed tutorial on how to get the desired coordinates and how to run the ship counting script, please refer to the 
													<a href='https://github.com/alexmak001/SAR-satelite-image-ship-detection'>GitHub Repo</a>)</i></li>
											</ul>
										 <li>Once the images are downloaded, each image will be preprocessed and split up into sub images one at a time.</li>
										 <li>Then, each sub image is classified as either inshore or offshore.</li>
										 <li>
											Once classified, the sub image will be fed into its respective object detection model and will
											be used to detect and count the number of ships present.
										 </li>
										<li>
											Finally, the counts for all the sub images will be aggregated together to give the total counts within the full sized image. 	
										</li> 
									</ol>

									<br>
									The following subsections will explain each step in more detail.
								</p>
							<br>

							<h2>Acquiring Images & Preprocessing</h2>
								<p>
									The data we intend to deploy our model on is the Sentinel-1 SAR image collection on Google Earth
									Engine. To access this data, the user inputs the coordinates of the desired area
									as well as the start and end dates that the user wants to pull from. The coordinates 
									can be found on the Google Earth Engine Code editor <i>(Please refer to the <a href='https://github.com/alexmak001/SAR-satelite-image-ship-detection'>GitHub Repo</a> 
									for more details.)</i> The set of images will then be downloaded locally as .tif files.
									<br><br> 
									Once downloaded, we have to do some additional cleaning of the image values because as you can see below, 
									the image appears to have a gray tint to it. Fixing this requires clipping images values from -20 to 0 
									where values less than -20 are set to -20 and values greater than 0 are set to 0. As you can see below, 
									it creates a much more contrasted and clearer image. From there,
									we pad black bars around the image so that when we split the image in the next step, we will get equally sized sub images.
								</p>
								<figure class="eg_classify_left">
									<img src="images/raw_port_la.jpg" alt='missing' width="100%" height="100%"/>
									<figcaption style="text-align:center; font-size:80%;">Raw Image from Google Earth Engine</figcaption>
								</figure>
								<figure style="margin-left: 20px">
									<img src="images/padded_port_la.jpg" alt='missing'  width="95%" height="95%"/>
									<figcaption style="text-align:center; font-size:80%;">Preprocessed Image</figcaption>
								</figure>
								<br>

								<h2>Inshore-Offshore Classifier</h2>
								<p>To build our inshore-offshore classifier, we trained on the Large-Scale SAR Ship Detection Dataset-v1.0(LS-SSDD-v1.0) dataset. This dataset 
									contains 15 large SAR images that are broken down into 9000 sub-images with varying presence of land, sea, and ships. Then to find the best model for classification
									we gathered a list of different machine learning models and assessed the average accuracy of each model on the dataset. From 
									this we found that the K-Nearest Neighbors model performed the best in terms of accuracy out of all the models.
									<br><br>
									Once we found the best model, we needed to find the best hyperparameters for our model to give us the best performance. 
									To do this we used a technique called Grid Search Cross Validation which essentially tries out different combinations of parameters in the model
									and outputs the best performing set of parameters. In our case, we found that our K-Nearest Neighbors model worked best with 5 neighbors, 
									kd_tree for the algorithm to compute the neighbors, and with the weights of each datapoint weighted uniformly.
									<br><br>

									<figure class="eg_classify_left">
										<img src="images/eg_inshore.jpg" alt='missing' width="95%" height="95%"/>
										<figcaption style="text-align:center; font-size:80%;">Example of image classified as inshore</figcaption>
									</figure>
									<figure style="margin-left: 20px">
										<img src="images/eg_offshore.jpg" alt='missing'  width="95%" height="95%"/>
										<figcaption style="text-align:center; font-size:80%;">Example of image classified as offshore</figcaption>
									</figure>
									
									
								</p>
								<h2>Object Detection Models</h2>
								<p>
									For detecting ships within inshore images we trained deep learning object detection model called Faster R-CNN. As we can see below, inshore images are often more 
									complicated with the presence of different land features. Due to this fact, detecting ships can be a little harder of a problem because of that we wanted 
									to use a more robust model that can handle such cases and will allow for more accurate detection of ships when faced with more complex images. 
									<br><br>
									In the opposite case of offshore images, these images are often much less information dense where images feature mostly open ocean and in some cases ships. 
									Since these images are not as complicated, we decided to use the faster and more lightweight model RetinaNet.  
									<br><br>
									Both of these models were built using the deep learning package Pytorch within Python. However, we ran into some problems where we could only use images
									with ships present in them to train the models. This cut down our total dataset size from 9,000 images to 1,900 images. We tried to fix this problem by introducing 
									image augmentations such as rotations and adding noise to try and increase the size of our dataset, but due to time constraints we were unable to implement these.
									However, to solve this issue we instead trained our models for more iterations. 
									<br><br>
								</p>
								<img src="images/fasterpredwater.png" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">Example of image with detected ships.</div>

					</section>

					<!-- Results -->	
					<section id="results" class="wrapper style1 fade-up">
						<div class="inner">
							<h1>Results</h1>
							<h3>Inshore-Offshore Classifier</h3><br>
								<img src="images/clf_bar.png" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">Average accuracies of classifiers</div><br>
								<img src="images/clf_results.png" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">Average accuracies and runtimes of classifiers</div><br>
							<p>
								As we can see from the bar graph and table above, the Decision Tree, Random Forest, and K-Nearest Neighbors
								models all performed quite similarly in terms of average accuracy and runtime. However, in the end we decided to go with the K-Nearest Neighbors model
								for its slightly better accuracy despite having a slightly slower runtime. This is because within our application, we want to ensure more accurate inshore/offshore 
								predictions so that the images are fed into their correct object detection models.    
							</p>

							<h3>Object Detection Models</h3><br>
								<img src="images/od_metric_full.png" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">bar graphs of metrics for object detection models</div><br>
								<img src="images/od_metrics.png" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">Table of metrics for object detection models</div><br>
							<p>
								From the above metrics, we can see that the Faster R-CNN had the highest accuracy scores, but was slowest on inference. Because of this, we decided to 
								go with Faster R-CNN for the more complicated inshore images. For the offshore images, we went with RetinaNet due to the fact that it performs almost as good
								as well as a little bit faster than Faster R-CNN. However, these speed and accuracy differences are quite small.
							</p>

							<h3>Full Pipeline</h3>
								<img src="images/tool_comparison.png" alt="Image 1" width="50%" height="50%" style="display: block; margin-left: auto; margin-right: auto; width: 50%;">
								<div style="width:image width px; text-align:center; font-size:80%;" id="img_caption2">bar graphs of metrics for object detection models</div><br>
							<p>
								We can see from above that our tool performs slightly faster than just using Faster R-CNN for both inshore and offshore, and does about the same performance wise.
								This tells us that our tool predicts just as well as Faster R-CNN, and we hope that the small speed increase will translate to scale.

								<br><br>
								<i>Note: All results from the inshore-offshore classifier and object detection models are derived from the test set of the 
									Large-Scale SAR Ship Detection Dataset-v1.0(LS-SSDD-v1.0) dataset.
								</i>
							</p>



					</section>

					
					<!-- Conclusion -->	
					<section id="conclusion" class="wrapper style1 fade-up">
						<div class="inner">
							<h1>Conclusion</h1>
							<p>Our goal is for the ship counting tool we have created to be used for other projects 
								such as political policy monitoring, or economic modeling. The modularity of it allows 
								for different parts of the tool to be easily replaced or reconfigured. For example, if a 
								new object detection model is created it can be easily trained and swapped with the current 
								one in the tool. Another example is if a new source of satellite imagery data becomes open source 
								or purchased it can be inputted into the tool instead of Google Earth Engine. Overall, we hope that 
								others continue to build upon this tool or apply it for a beneficial purpose.</p>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; 2023 Alex Makhratchev & Sean Ng. All Rights Reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						<li><a href="https://github.com/alexmak001/SAR-satelite-image-ship-detection" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						<li><a href='about.html'><span>&#x1F6C8;</span></a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
	 

	</body>
</html>
